{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "import torch\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "import accelerate\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"new_updated_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training text: ['At a time when computers were a short step removed from mechanical data processors, Licklider was writing treatises on \"human-computer symbiosis,\" \"computers as communication devices,\" and a now not-so-unfamiliar \"Intergalactic Network.\" His ideas became so influential, his passion so contagious, that Waldrop coined him \"computing\\'s Johnny Appleseed.\" In a simultaneously compelling personal narrative and comprehensive historical exposition, Waldrop tells the story of the man who not only instigated the work that led to the internet, but also shifted our understanding of what computers were and could be.', \"Winner of the Pulitzer Prize, this book applies Godel's seminal contribution to modern mathematics to the study of the human mind and the development of artificial intelligence.\", '', \"The Gene: An Intimate History is a book written by Siddhartha Mukherjee, an Indian-born American physician and oncologist. It was published on 17 May 2016 by Scribner. The book chronicles the history of the gene and genetic research, all the way from Aristotle to Crick, Watson and Franklin and then the 21st century scientists who mapped the human genome. The book discusses the power of genetics in determining people's well-being and traits. It delves into the personal genetic history of Siddhartha Mukherjee's family, including mental illness. However, it is also a cautionary message toward not letting genetic predispositions define a person or their fate, a mentality that the author says led to the rise of eugenics in history.\", '']\n",
      "dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"new_updated_data.csv\")\n",
    "\n",
    "# Ensure descriptions are strings and handle missing values\n",
    "df[\"description\"] = df[\"description\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Ensure tropes are lists of labels\n",
    "df[\"tags\"] = df[\"tags\"].apply(lambda x: x.split(\", \") if isinstance(x, str) else [])\n",
    "\n",
    "# Split data into training and testing\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"description\"].tolist(), df[\"tags\"].tolist(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check for any unexpected non-string values\n",
    "print(f\"Sample training text: {train_texts[:5]}\")  # Should print valid book descriptions\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KamilAin/bart-base-booksum\")\n",
    "\n",
    "# Tokenize descriptions only\n",
    "train_encodings = tokenizer(\n",
    "    train_texts, truncation=True, padding=True, max_length=512\n",
    ")\n",
    "test_encodings = tokenizer(\n",
    "    test_texts, truncation=True, padding=True, max_length=512\n",
    ")\n",
    "\n",
    "# Print sample output\n",
    "print(train_encodings.keys())  # Should print: dict_keys(['input_ids', 'attention_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Tags: [' American' ' Ancient' ' Australian' ' China' ' Chinese' ' Classified'\n",
      " ' Dutch' ' English' ' Folk Tales' ' Greek' ' Human' ' Korean'\n",
      " ' Latin American' ' Legends & Mythology' ' Mind & Spirit' ' Mythical'\n",
      " ' Personal' ' Subterranean' ' Swiss (German)' ' Viking' ' artistic'\n",
      " 'Abandoned children' 'Abduction' 'Ability' 'Abnormalities'\n",
      " 'Absentee fathers' 'Abuse' 'Abuse of administrative power' 'Abused'\n",
      " 'Abused teenagers' 'Abused wives' 'Abused women' 'Abusive men'\n",
      " 'Academic writing' 'Accident victims' 'Accidents' 'Action'\n",
      " 'Action and adventure' 'Activism' 'Actresses' 'Addicts' 'Adolescence'\n",
      " 'Adolescent psychology' 'Adoptees' 'Adoption' 'Adult Fiction' 'Adultery'\n",
      " 'Adulthood' 'Adventure' 'Adventure and adventurers' 'Adventure stories'\n",
      " 'Advice' 'African American authors' 'African American families'\n",
      " 'African American gay men' 'African American girls'\n",
      " 'African American teenage girls' 'African Americans'\n",
      " 'African Americans in mass media' 'Africans' 'Aging' 'Agriculture'\n",
      " 'Air warfare' 'Alchemists' 'Alchemy' 'Alcoholics' 'Alcoholism'\n",
      " 'Algorithms' 'Aliens' 'Allegories' 'Alliances' \"Alzheimer's disease\"\n",
      " 'Amazon River Region' 'Ambassadors' 'Ambition' 'American'\n",
      " 'American Dream' 'American drama' 'American fiction'\n",
      " 'American literature' 'Americans' 'Amnesia' 'Amnesiacs' 'Anarchism'\n",
      " 'Anecdotes' 'Angels' 'Animal behavior' 'Animal communication'\n",
      " 'Animal rights' 'Animals' 'Anonymous persons' 'Antarctica' 'Anthology'\n",
      " 'Anthropology' 'Anti-racism' 'Antiheroes' 'Antineoplastic agents'\n",
      " 'Antiquities' 'Antislavery movements' 'Anxiety disorders'\n",
      " 'Anxiety in adolescence' 'Apartment houses' 'Apocalypse'\n",
      " 'Appointment books' 'Apprentices' 'Archetype' 'Architects'\n",
      " 'Arctic regions' 'Aristocracy (Social class)' 'Arms race'\n",
      " 'Arranged marriage' 'Art' 'Art and music' 'Artificial Intelligence'\n",
      " 'Artificial intelligence.' 'Artificial life' 'Artists' \"Artists' books\"\n",
      " 'Arts' 'Asexuality' 'Asia' 'Asian American women' 'Asian Americans'\n",
      " 'Asian Literature' 'Assasins' 'Assassins' 'Astronauts' 'Astronomy'\n",
      " 'Astrophysics' 'Attempted assassination' 'Attempted murder' 'Attention'\n",
      " 'Australia' 'Autobiographical fiction' 'Autoimmune diseases' 'BDSM'\n",
      " 'Ballerinas' 'Balls (Parties)' 'Bands (Music)' 'Barbarians'\n",
      " 'Basic income' 'Battles' 'Beauty' 'Behavior' 'Belief and doubt'\n",
      " 'Best friends' 'Best sellers' 'Betrayal' 'Big data' 'Bioengineering'\n",
      " 'Biographers' 'Biography' 'Biography & Autobiography' 'Biography Memoir'\n",
      " 'Biology' 'Bishop' 'Black Death' 'Black Love' 'Blessing and cursing'\n",
      " 'Blind' 'Blizzards' 'Blue collar workers' 'Boarding school' 'Body'\n",
      " 'Bodyguards' 'Books' 'Books About Books' 'Books and reading' 'Bookstores'\n",
      " 'Botany' 'Boys' 'Brainwashing' 'Brennan' 'British' 'Broadsides'\n",
      " 'Brotherhoods' 'Brothers' 'Buddhist gods' 'Buddhist nuns' 'Bullies'\n",
      " 'Bully Romance' 'Bureaucracy' 'Business' 'Business & Economics'\n",
      " 'Business communication' 'Business ethics' 'Business intelligence'\n",
      " 'Businessmen' 'Businesswomen' 'Camps' 'Canada' 'Cancer' 'Cannibalism'\n",
      " 'Capitalism' 'Caregivers' 'Caribbean' 'Carnival owners' 'Carnivals'\n",
      " 'Carnivorous plants' 'Caste' 'Castles' 'Celebrities' 'Chance'\n",
      " 'Chemical warfare' 'Chess' 'Chick Lit' 'ChickLit'\n",
      " 'Chief executive officers' 'Child abuse' 'Children'\n",
      " 'Children of Holocaust survivors' \"Children's Literature\"\n",
      " \"Children's poetry\" \"Children's stories\" 'China' 'Choice'\n",
      " 'Christian Fiction' 'Christianity' 'Christmas' 'Christmas stories'\n",
      " 'Chronology' 'Cities and towns' 'City and town life' 'City planners'\n",
      " 'Civil war' 'Civilization' 'Clairvoyance' 'Clairvoyants' 'Clans'\n",
      " 'Classical fiction' 'Classics' 'Clergy' 'Climate and civilization'\n",
      " 'Climatic changes' 'Clubs' 'Coffee shops' 'Cognition'\n",
      " 'Cold cases (Criminal investigation)' 'College' 'College Romance'\n",
      " 'College graduates' 'College stories' 'College students' 'Coma' 'Comics'\n",
      " 'Comics & Graphic Novels' 'Coming of Age' 'Communists' 'Community life'\n",
      " 'Computer Science' 'Computer games' 'Computer hackers'\n",
      " 'Computer software' 'Computers' 'Concentration camps' 'Conduct of life'\n",
      " 'Conspiracies' 'Conspiracy' \"Consumers' preferences\"\n",
      " 'Consumption (Economics)' 'Contemporary' 'Contemporary Fiction'\n",
      " 'Contemporary Romance' 'Contests' 'Cookbook' 'Cooking' 'Corporations'\n",
      " 'Corruption' 'Country life' 'Couples' 'Cousins' 'Covenant'\n",
      " 'Cowboy Romance' 'Cowboys' 'Crafts & Hobbies' 'Crime' 'Crime Fiction'\n",
      " 'Crime investigation' 'Crime investigations' 'Criminal investigation'\n",
      " 'Critical thinking' 'Cults' 'Curiosities and wonders'\n",
      " 'Custody of children' 'Cyberculture' 'Cyborgs' 'Czech fiction'\n",
      " 'DC Comics' 'Dark' 'Dark Academia' 'Dark Comedy' 'Dark Fantasy'\n",
      " 'Dark Romance' 'Data' 'Data Visualization' 'Dead' 'Deaf people' 'Death'\n",
      " 'Debt' 'Deception' 'Decision making' 'Defection' 'Demoniac possession'\n",
      " 'Demonology' 'Deportation' 'Depression' 'Design'\n",
      " 'Detective and mystery fiction' 'Detective and mystery stories'\n",
      " 'Detectives' 'Developing countries' 'Devil' 'Dictators' 'Dictatorship'\n",
      " 'Dinosaurs' 'Diophantine analysis' 'Disability' 'Disasters'\n",
      " 'Divorced people' 'Dogs' 'Domestic drama' 'Domestic fiction' 'Drama'\n",
      " 'Dreams' 'Drugs' 'Dune (Imaginary place)' 'Dungeons and Dragons (Game)'\n",
      " 'Dwarfs' 'Dystopian' 'Early memories' 'Earth (Planet)' 'Economics'\n",
      " 'Education' 'Egypt' 'Electronic books' 'Emotional problems' 'Emotions'\n",
      " 'Emperors' 'End of the world' 'Enemies to lovers' 'Energy policy'\n",
      " 'England' 'English drama' 'Entitlement attitudes' 'Entrepreneurship'\n",
      " 'Environmental degradation' 'Epic Fantasy' 'Epic Poetry' 'Epidemics'\n",
      " 'Erotic stories' 'Erotica' 'Errors' 'Escort services' 'Espionage' 'Essay'\n",
      " 'Essays' 'Ethics' 'Ethnic relations' 'Evolution' 'Evolution (Biology)'\n",
      " 'Existentialism' 'Extortion' 'Extraterrestrial beings' 'Fables' 'Fairies'\n",
      " 'Fairy Tale Retelling' 'Fairy tales' 'Falconry' 'Fame' 'Families'\n",
      " 'Family' 'Family & Relationships' 'Family secrets' 'Fanfiction'\n",
      " 'Fantastic fiction' 'Fantasty fiction' 'Fantasy' 'Fantasy comic books'\n",
      " 'Fantasy fiction' 'Fantasy games' 'Fantasy romance' 'Fantasy.'\n",
      " 'Fashion editors' 'Fate and fatalism' 'Fathers' 'Fathers and daughters'\n",
      " 'Fathers and sons' 'Fear' 'Female friendship' 'Feminism'\n",
      " 'Feminist Theory' 'Feminist ethics' 'Feminist fiction' 'Fiction'\n",
      " 'Figure skaters' 'Film' 'Finance' 'Flight attendants' 'Folklore' 'Food'\n",
      " 'Foreign Language Study' 'Forensic Science' 'Forests and forestry'\n",
      " 'Forgers' 'Foster home care' 'France' 'Fraud' 'French drama'\n",
      " 'French literature' 'Friends' 'Friendship' 'Fugitives from justice'\n",
      " 'Games' 'Games & Activities' 'Gay' 'Gay men' 'Gay teenagers'\n",
      " 'Gender identity' 'General' 'Genetic engineering' 'Geography'\n",
      " 'German fiction' 'German language' 'Germany' 'Ghosts & Hauntings' 'God'\n",
      " 'Goddesses' 'Gods and goddesses' 'Good and evil' 'Gossip' 'Gothic'\n",
      " 'Gothic Horror' 'Gothic novels' 'Government' 'Government investigators'\n",
      " 'Governors' 'Graphic novels' 'Great Britain' 'Grief' 'Guilt' 'Habit'\n",
      " 'Hackers' 'Hallucinogenic drugs' 'Haunted House' 'Haunted houses'\n",
      " 'Health' 'Health & Fitness' 'Heist' 'Hell' 'High Fantasy' 'High school'\n",
      " 'High school students' 'High technology industries' 'Historians'\n",
      " 'Historical' 'Historical Fantasy' 'Historical Fiction'\n",
      " 'Historical Mystery' 'Historical Romance' 'History' 'Hockey Romance'\n",
      " 'Holiday' 'Holocaust' 'Homecoming' 'Homeless children' 'Homelessness'\n",
      " 'Horror' 'Horror fiction' 'House & Home' 'Housekeepers' 'Human behavior'\n",
      " 'Human-animal relationships' 'Humanities' 'Humanity' 'Humorous fantasy'\n",
      " 'Humorous fiction' 'Humorous stories' 'Husbands' 'Identity (Psychology).'\n",
      " 'Illness' 'Imaginary places' 'Imaginary wars and battles' 'Immigrants'\n",
      " 'Immortalism' 'Immortality' 'India' 'Indonesia' 'Indonesian language'\n",
      " 'Industrial productivity' 'Industrial relations' 'Information technology'\n",
      " 'Innovation' 'Inspirational' 'Intelligence officers'\n",
      " 'Intelligence service' 'Interplanetary voyages' 'Introversion'\n",
      " 'Investing' 'Investments' 'Irish Americans' 'Islam and politics' 'Japan'\n",
      " 'Japanese fiction' 'Japanese literature' 'Journal' 'Journalists'\n",
      " 'Justice' 'Juvenile Fiction' 'Juvenile Nonfiction' 'Kidnapping'\n",
      " 'Kidnapping victims' 'Knowledge' 'Korea (North)' 'LGBTQ'\n",
      " 'LGBTQ Literature' 'Labor camps' 'Language Arts & Disciplines'\n",
      " 'Language and languages' 'Law' 'Leadership' 'Lesbians'\n",
      " 'Life on other planets' 'Linguistics' 'Literary' 'Literary Collections'\n",
      " 'Literary Fiction' 'Literature' 'Love stories' 'M M Romance' 'Mafia'\n",
      " 'Mafia Romance' 'Magic' 'Magic Realism' 'Magic realism (Literature)'\n",
      " 'Magical Realism' 'Magical School' 'Male domination' 'Manga' 'Manors'\n",
      " 'Manuscripts' 'Marathon running' 'Materials science' 'Medical'\n",
      " 'Medical examiners (Law)' 'Memoir' 'Memory' 'Mental discipline'\n",
      " 'Mental health' 'Mental illness' 'Mentally ill' 'Mexico' 'Middle Ages'\n",
      " 'Middle East' 'Middle Grade' 'Military' 'Military Fiction' 'Minimum wage'\n",
      " 'Missing persons' 'Monsters' 'Mothers' 'Mountaineering expeditions'\n",
      " 'Murder' 'Music' 'Mystery' 'Mystery fiction' 'Mystical powers'\n",
      " 'Mysticism' 'Mythological' 'Mythology' 'Native American Literature'\n",
      " 'Native Americans' 'Nature' 'Nature stories' 'Neo-Western' 'Neurology'\n",
      " 'Neuroscience' 'New adult' 'New adult fantasy' 'Nigeria' 'Noir'\n",
      " 'Nonfiction' 'Novella' 'Odysseus (Greek mythology)' 'Omegaverse'\n",
      " 'Overpopulation' 'Paranormal' 'Paranormal Romance' 'Paranormal romance'\n",
      " 'Parenting' 'Pedagogy' 'Performing Arts' 'Period piece' 'Period romance'\n",
      " 'Personal Development' 'Philosophers' 'Philosophical' 'Philosophy'\n",
      " 'Plays' 'Poetry' 'Police' 'Political corruption' 'Politics'\n",
      " 'Popular literature' 'Post Apocalyptic' 'Post World War'\n",
      " 'Post-Apocalyptic Science Fiction' 'Presidents' 'Prisoners'\n",
      " 'Prisoners of war' 'Private schools' 'Productivity' 'Programming'\n",
      " 'Progression Fantasy' 'Psychological thriller' 'Psychology'\n",
      " 'Psychotherapists' 'Puzzles' 'Queer' 'Queer Manga' 'Race' 'Racism'\n",
      " 'Rationalism' 'Refugees' 'Regency Romance' 'Reincarnation'\n",
      " 'Relationships' 'Religion' 'Religion & Spirituality' 'Renaissance'\n",
      " 'Retelling' 'Retellings' 'Robots' 'Romance' 'Romance fiction' 'Romantasy'\n",
      " 'Romantic Comedy' 'Romantic Suspense' 'Romantic fantasy' 'Rome' 'Russia'\n",
      " 'Russian Literature' 'Russian fiction' 'STEM' 'Satire' 'Science'\n",
      " 'Science fiction' 'Science fiction romance' 'Scotland' 'Screenplay'\n",
      " 'Seas' 'Self help' 'Self-Help' 'Sex instruction for women'\n",
      " 'Shipwreck survival' 'Short stories' 'Siblings' 'Sisters' 'Slice of life'\n",
      " 'Smutty' 'Social Issues' 'Sociology' 'Solarpunk' 'Soviet Union' 'Space'\n",
      " 'Space Horror' 'Space Opera' 'Space colonies' 'Space warfare' 'Spanish'\n",
      " 'Spanish fiction' 'Spanish literature' 'Speeches' 'Spicy' 'Spiritualism'\n",
      " 'Spirituality' 'Sports' 'Sports & Recreation' 'Sports Romance' 'Spy'\n",
      " 'Stalker' 'Steampunk' 'Stoicism' 'Success' 'Supernatural' 'Surfers'\n",
      " 'Survival' 'Suspense' 'Suspense fiction' 'Sweden' 'Sword and Sorcery'\n",
      " 'Technology' 'Technology & Engineering' 'Teenagers' 'Television plays'\n",
      " 'Tennis stories' 'Thriller' 'Time Travel' 'Tragedy' 'Trauma' 'Travel'\n",
      " 'True crime' 'US History' 'Undertakers and undertaking' 'United States'\n",
      " 'Urban Fantasy' 'Vampires' 'Veganism' 'Vietnam' 'Vietnam War' 'WW2' 'War'\n",
      " 'Western' 'Whodunnit' 'Widows' 'Womanhood' 'Women' 'Women lawyers'\n",
      " 'World War' 'World War I' 'Writing' 'Young Adult' 'Young Adult Fiction'\n",
      " 'Young Adult Fiction / Mysteries & Detective Stories'\n",
      " 'Young Adult Romance' 'Young Sleuth' 'Young adult fantasy' 'adult'\n",
      " 'adult romances' 'adventurous' 'alien' 'alternate history'\n",
      " 'autobiography' 'comedy' 'communism' 'cosy mystery' 'cyberpunk'\n",
      " 'detective' 'dragons' 'dystopian' 'erotica' 'fae' 'furry' 'gods'\n",
      " 'greek mythology' 'ideology' 'indigenous' 'informative' 'lgbtqia+'\n",
      " 'literary criticism' 'literary horror' 'low fantasy' 'medieval'\n",
      " 'multimedia' 'multiverse' 'murder mystery' 'non-fiction' 'picture book'\n",
      " 'political science' 'pulp fiction' 'quest' 'reference' 'relationships'\n",
      " 'romcom' 'romcoms' 'science fantasy' 'science fiction fantasy'\n",
      " 'science-fiction' 'short story' 'social science' 'tech development'\n",
      " 'teen' 'vigilante' 'warfare' 'witches' 'women' 'zombies']\n",
      "Sample Encoded Labels: [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Convert tags (tropes) into multi-hot encoding\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(df[\"tags\"])  # Learn all unique tags\n",
    "train_labels = mlb.transform(train_labels)  # Convert to binary labels\n",
    "test_labels = mlb.transform(test_labels)\n",
    "\n",
    "# Print sample labels\n",
    "print(\"Unique Tags:\", mlb.classes_)  # Check all unique tropes\n",
    "print(\"Sample Encoded Labels:\", train_labels[:5])  # One-hot encoded output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Convert tokenized data into dataset format\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": train_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": train_encodings[\"attention_mask\"],\n",
    "    \"labels\": train_labels.tolist(),\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": test_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": test_encodings[\"attention_mask\"],\n",
    "    \"labels\": test_labels.tolist(),\n",
    "})\n",
    "\n",
    "# Convert to Hugging Face DatasetDict format\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-24 12:27:46,603] A new study created in memory with name: no-name-8b8eefdc-d085-4f53-bc6b-7cbe0db24ee4\n",
      "C:\\Users\\maheit\\AppData\\Local\\Temp\\ipykernel_2492\\1754616738.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-4)\n",
      "C:\\Users\\maheit\\AppData\\Local\\Temp\\ipykernel_2492\\1754616738.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 0.1)\n",
      "c:\\Users\\maheit\\dev\\book\\lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[W 2025-02-24 12:27:47,480] Trial 0 failed with parameters: {'learning_rate': 1.9225378797319263e-05, 'batch_size': 16, 'weight_decay': 0.004201119575329948} because of the following error: NameError(\"name 'dataset' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\maheit\\dev\\book\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\maheit\\AppData\\Local\\Temp\\ipykernel_2492\\1754616738.py\", line 39, in objective\n",
      "    train_dataset=dataset[\"train\"],\n",
      "NameError: name 'dataset' is not defined. Did you mean: 'Dataset'?\n",
      "[W 2025-02-24 12:27:47,481] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 54\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Run Optuna optimization\u001b[39;00m\n\u001b[0;32m     53\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Minimize validation loss\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Run 10 trials (increase if needed)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Get best hyperparameters\u001b[39;00m\n\u001b[0;32m     57\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\maheit\\dev\\book\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maheit\\dev\\book\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\maheit\\dev\\book\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\maheit\\dev\\book\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\maheit\\dev\\book\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[3], line 39\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     33\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKamilAin/bart-base-booksum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Define Trainer\u001b[39;00m\n\u001b[0;32m     36\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     37\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     38\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m---> 39\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mdataset\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     40\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mdataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     41\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)],  \u001b[38;5;66;03m# Stops if no improvement for 2 epochs\u001b[39;00m\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m     45\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# Define objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 5e-4)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 0.1)\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=10,  # Higher number since early stopping is enabled\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        logging_dir=\"./logs\",\n",
    "        report_to=\"none\",  # Prevents logging to external services\n",
    "    )\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"KamilAin/bart-base-booksum\")\n",
    "    \n",
    "    # Define Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"test\"],\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],  # Stops if no improvement for 2 epochs\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate model on validation set\n",
    "    eval_results = trainer.evaluate()\n",
    "    \n",
    "    return eval_results[\"eval_loss\"]\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"minimize\")  # Minimize validation loss\n",
    "study.optimize(objective, n_trials=10)  # Run 10 trials (increase if needed)\n",
    "\n",
    "# Get best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
